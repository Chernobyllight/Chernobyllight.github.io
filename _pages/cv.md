---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
======
* M.S. in Sun Yat-sen University (SYSU), 2026 (expected)
* B.S. in University of Electronic Science and Technology of China (UESTC), 2023


Publications
======
* SaMam: Style-aware State Space Model for Arbitrary Image Style Transfer [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_SaMam_Style-aware_State_Space_Model_for_Arbitrary_Image_Style_Transfer_CVPR_2025_paper.html)] [[code](https://github.com/Chernobyllight/SaMam)]
* Pluggable Style Representation Learning for Multi-Style Transfer [[paper](https://openaccess.thecvf.com/content/ACCV2024/html/Liu_Pluggable_Style_Representation_Learning_for_Multi-Style_Transfer_ACCV_2024_paper.html)] [[code](https://github.com/Chernobyllight/SaMST)]
* NTIRE 2024 Challenge on Stereo Image Super-Resolution: Methods and Results [[paper](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Wang_NTIRE_2024_Challenge_on_Stereo_Image_Super-Resolution_Methods_and_Results_CVPRW_2024_paper.html) [[track1](https://codalab.lisn.upsaclay.fr/competitions/17245)] [[track2](https://codalab.lisn.upsaclay.fr/competitions/17246)]
* Preserving Full Degradation Details for Blind Image Super-Resolution [paper](https://arxiv.org/abs/2407.01299)] [[code](https://github.com/Chernobyllight/ReDSR)]
* Deploying Large AI Models on Resource-Limited Devices with Split Federated Learning [[paper](https://arxiv.org/abs/2504.09114)]


  

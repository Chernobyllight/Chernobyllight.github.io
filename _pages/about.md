---
permalink: /
title: "Welcome to Hongda Liu's Personal Homepage!"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I am currently in my third year of pursuing a master degree at Sun Yat-sen University (SYSU). My advisors are [Yulan Guo](https://www.yulanguo.cn/) and [Longguang Wang](https://longguangwang.github.io/). I received my B.S. degree from the School of Information and Software Engineering, University of Electronic Science and Technology of China (UESTC) in 2023.

My current research interests include low-level vision, specifically image/video restoration, as well as image/video style transfer. Besides, I have extensive experience in image/video generation and editing.

## :book: Education

* *2023.09 - 2026.06 (expected)*, M.S. in Sun Yat-sen University (SYSU)
* *2019.09 - 2023.06*, B.S. in University of Electronic Science and Technology of China (UESTC)

## :fire: News


## :books: Publications


<!-- <div style="display: flex; align-items: center;">
  <img src="/images/samam2.png"  style="margin-right: 10px; width: 200px; " />
  <p>SaMam: Style-aware State Space Model for Arbitrary Image Style Transfer</p>
</div> -->


|  |  |
|-------|----------|
| <img src="/images/samam2.png" style="width: 300px;"> | SaMam: Style-aware State Space Model for Arbitrary Image Style Transfer<br/>[[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_SaMam_Style-aware_State_Space_Model_for_Arbitrary_Image_Style_Transfer_CVPR_2025_paper.html)] [[code](https://github.com/Chernobyllight/SaMam)] |
| <img src="/images/SaMST.png" style="width: 300px;"> | Pluggable Style Representation Learning for Multi-Style Transfer |



<div style="display: flex; flex-direction: column; gap: 16px;">
  <div style="display: flex; align-items: flex-start; gap: 20px;">
    <img src="/images/samam2.png" alt="SaMam" style="width: 250px;">
    <div>
      <strong>SaMam: Style-aware State Space Model for Arbitrary Image Style Transfer</strong><br/>
      CVPR<br/>
      <strong>Hongda Liu</strong><br/>
      <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Liu_SaMam_Style-aware_State_Space_Model_for_Arbitrary_Image_Style_Transfer_CVPR_2025_paper.html">[paper]</a> 
      <a href="https://github.com/Chernobyllight/SaMam">[code]</a>
    </div>
  </div>
  <div style="display: flex; align-items: flex-start; gap: 20px;">
    <img src="/images/SaMST.png" alt="SaMST" style="width: 250px;">
    <div>
      <strong>Pluggable Style Representation Learning for Multi-Style Transfer</strong>
    </div>
  </div>
</div>


* SaMam: Style-aware State Space Model for Arbitrary Image Style Transfer [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_SaMam_Style-aware_State_Space_Model_for_Arbitrary_Image_Style_Transfer_CVPR_2025_paper.html)] [[code](https://github.com/Chernobyllight/SaMam)]
* Pluggable Style Representation Learning for Multi-Style Transfer [[paper](https://openaccess.thecvf.com/content/ACCV2024/html/Liu_Pluggable_Style_Representation_Learning_for_Multi-Style_Transfer_ACCV_2024_paper.html)] [[code](https://github.com/Chernobyllight/SaMST)]
* NTIRE 2024 Challenge on Stereo Image Super-Resolution: Methods and Results [[paper](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Wang_NTIRE_2024_Challenge_on_Stereo_Image_Super-Resolution_Methods_and_Results_CVPRW_2024_paper.html)] [[track1](https://codalab.lisn.upsaclay.fr/competitions/17245)] [[track2](https://codalab.lisn.upsaclay.fr/competitions/17246)]

## :computer: Internship

